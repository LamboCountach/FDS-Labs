{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inf2 - Foundations of Data Science\n",
    "## S2 Week 01: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning outcomes:** In this lab you will learn about logistic regression, interpretation of logistic regression coefficients and generating confidence intervals for logistic regression coefficients. By the end of this lab you should be able to:\n",
    "\n",
    "- identify what transformations would be helpful to variables before applying logistic regression\n",
    "- apply logistic regression to a dataset\n",
    "- interpret the coefficients from application of logistic regression\n",
    "- apply the bootstrap to logistic regression to obtain confidence intervals\n",
    "- interpret the confidence intervals\n",
    "\n",
    "**Remark:** The lecture topic on \"Logistic regression\" will be helpful background for this lab.\n",
    "\n",
    "**Data information:** We will look at the credit approval dataset, which we have already looked at during the lectures, and we will try to reconstruct the results ourselves. The dataset was originally published on the [UCI repository with the attribute names and values changed to meaningless symbols](https://archive.ics.uci.edu/ml/datasets/credit+approval). We have used [this version of the dataset](https://github.com/KiranmayiR/Credit_Shiny), in which the attribute names have been inferred. However, we have changed some attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Prepare the data\n",
    "\n",
    "Our goal is to use logistic regression to understand what features are most important in the decision of giving an applicant a credit.\n",
    "\n",
    "**Exercise 01:** The first step is to clean our dataset.\n",
    "- Load the dataset.\n",
    "- Display the first 20 entries.\n",
    "- Remove all entries with `NaN` values. (Hint: This data set has `?` characters instead of `NaN values).\n",
    "- Replace all non-numeric values by reasonable numeric values. Hint: we suggest you interpret `t` as `True` and `f` as `False`.\n",
    "- For simplicity, drop the `ZipCode` column.\n",
    "\n",
    "**Remark:** Zip codes can have an impact on credit approval. For example, ML algorithms trained on racially biased data, where the information about race has been dropped, can still learn the bias, as people from same ethnic background tend to live in the same area. However, for logistic regression the zip code is unlikely provide any information, as two zip codes that differ by a single digit can be many miles apart. We could consider whether this is the case if we used $k$-Nearest-Neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "credit = pd.read_csv('datasets/Credit_Approval.csv')\n",
    "credit.head()\n",
    "# credit.replace('?', pd.NA, inplace=True)\n",
    "credit.dropna(inplace=True)\n",
    "credit.replace('+', 1, inplace=True)\n",
    "credit.replace('-', 0, inplace=True)\n",
    "credit['Gender']=credit['Gender'].replace('a', 0)\n",
    "credit['Gender']=credit['Gender'].replace('b', 1)\n",
    "credit['Employed']=credit['Employed'].replace('f', 0)\n",
    "credit['Employed']=credit['Employed'].replace('t', 1)\n",
    "credit['NoPriorDefault']=credit['NoPriorDefault'].replace('f', 0)\n",
    "credit['NoPriorDefault']=credit['NoPriorDefault'].replace('t', 1)\n",
    "credit['DriversLicense']=credit['DriversLicense'].replace('f', 0)\n",
    "credit['DriversLicense']=credit['DriversLicense'].replace('t', 1)\n",
    "credit.drop(['ZipCode'], axis=1, inplace=True)\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 02:** Let's compare the values for the two genders. Compute the mean of the columns for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "credit.groupby('Gender').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 03:**\n",
    "- Create a pairplot of the data, giving approved and denied applications different colours. \n",
    "- As you can see there too many variables. Remove variables from the pairplot that you think are not displayed helpfully in a pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "plt.figure(figsize=(6,6))\n",
    "# We removed the binary values, as they do not show much in a pairplot\n",
    "sns.pairplot(credit.drop(['Gender', 'NoPriorDefault', 'Employed', 'DriversLicense'], axis=1), hue='Approved')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Transform the dataset so logistic regression works better\n",
    "\n",
    "**Discussion:** We have already applied the log transform to datasets previously.\n",
    "- Can you remember why this can be helpful?\n",
    "- For which variables in your dataset would a log transform help? Have a look at the plot above.\n",
    "- Can you think of data points the log transform might not work for, and how the transform could be modified to fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "- If the data is skewed, a log-transformation can help to make the distribution of the data closer to a normal distribution.\n",
    "- Both Income and Credit score seem very skewed.\n",
    "- If we have a value that is equal to 0, we are taking the log of zero, which is not defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 04:** \n",
    "- Replace the `Income` variable by transforming it with a function $f(x) = \\log_{10} (x + 1)$ to give a version called `LogIncome`.\n",
    "- Repeat the above step with the `CreditScore` variable to give a log transformed version called `LogCreditScore`.\n",
    "- Plot a new pairplot to see the new distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "credit['LogIncome'] = np.log10(credit['Income'] + 1)\n",
    "credit['LogCreditScore'] = np.log(credit['CreditScore'] + 1)\n",
    "credit.drop(['Income', 'CreditScore'], axis=1, inplace=True)\n",
    "sns.pairplot(credit.drop(['Gender', 'NoPriorDefault', 'Employed', 'DriversLicense'], axis=1), hue='Approved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Use sk-learn to run Logistic regression\n",
    "\n",
    "**Exercise 05:** Let's start with the simplest case of logistic regression. We want to know whether age alone is a good feature to predict whether someone receives a credit. \n",
    "- Use the `LogisticRegression()` to run logistic regression. (Hint: You will have to supply a numpy matrix of independent variables and a vector of response variables - the Nearest Neighbours lab may remind you how to do it.)\n",
    "- Store the fitted model.\n",
    "- Store the intercept and the coefficient of the model in `beta0` and `beta1`, respectively. Print the values.\n",
    "- Create a scatterplot, in which, to make it intelligible, you randomly sample 50 data points. The x-axis should be `Age` and the y-axis should be `Approved`.\n",
    "- Add a line plot to your figure that shows the probability predicted by the logistic regression. **Hint:** The sklearn `predict_proba()` function can be applied to the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "X = credit[['Age']].to_numpy(copy=True) \n",
    "y = credit['Approved'].to_numpy()\n",
    "model = LogisticRegression().fit(X, y)\n",
    "beta0 = model.intercept_[0]\n",
    "beta1 = model.coef_[0][0]\n",
    "print(\"Beta 0: \" + str(beta0) + \", Beta 1: \" + str(beta1))\n",
    "plt.figure()\n",
    "\n",
    "sns.scatterplot(x='Age', y='Approved', data=credit.sample(50))\n",
    "x = np.arange(credit.Age.min(), credit.Age.max(), 0.1)\n",
    "plt.plot(x, model.predict_proba(np.reshape(x, (-1, 1)))[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Interpret the intercept `model.intercept_`, which is the same as $\\hat\\beta_0$ in the lecture notes. What quantity does it represent? Describe the characteristics of the customer for who the independent variables are all zero. Does such a customer exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "This is the log odds of approval of credit for a customer aged 0. They are $e^{-1.162}=0.313$ times as likely to be approved as to be declined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 06:** Above we have run the logistic regression on only one independent variable in order to be able to plot it in a figure. Now, run a logistic regression on the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "X = credit.drop(columns=['Approved']).to_numpy(copy=True) \n",
    "y = credit['Approved'].to_numpy()\n",
    "model = LogisticRegression().fit(X, y)\n",
    "beta0 = model.intercept_[0]\n",
    "beta1 = model.coef_[0]\n",
    "print(\"Beta 0: \" + str(beta0) + \", Beta 1: \" + str(beta1))\n",
    "\n",
    "## Display as Series with names to aid explanation\n",
    "coeffs = pd.concat([pd.Series({'Intercept': beta0}),\n",
    "                    pd.Series(beta1, index=credit.columns[credit.columns != 'Approved'])])\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Interpret the coefficients `model.coef_`. You may find it helpful to convert the output from sklearn back into a pandas Series with an index. Try to use language that you think would be understandable by a general audience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "A weighting system is used to determine if your request for credit is approved. You start off with a  score of -2.955. If you are male (we think) you add 0.011, and you subtract -0.013 for every year of your age. You add 0.004623 for every unit of debt you have, and also add 0.14 for every year of employment. If you have not defaulted on a loan, you add 3.317. You subtract -0.082 if you're employed and -0.103 if you have a Driver's license. You round your income to the nearest 10, 100, 1000 or 10,000 etc, multiply the number of zeros in this rounded number by 0.34, and add it to the score. You do the same for your credit score (if you know it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. How many of these coefficients are meaningful?\n",
    "\n",
    "How likely is it that some of these coefficients could have arisen by chance? We'd like to find confidence intervals for each coefficient. \n",
    "\n",
    "**Excercise 07:** Write a bootstrap function to generate the sampling distribution of all of the coefficients. On each bootstrap iteration, we'd like to store the values of the intercept and all of the coefficients in one row of a dataframe. We'll then be able to plot distribution of the dataframe, and compute confidence intervals from the marginal distributions. We suggest you follow the pattern in the previous lab, and write:\n",
    "1. A function that takes a dataframe with the same column names as the credit approval dataset, fits a logistic regression model to the dataset and returns a pandas series containing the intercept and coefficients from the logistic regression\n",
    "2. A bootstrap function that takes the above function as an `estimator` argument, and, on each bootstrap replication, stores the coefficients in the row of a data frame. It should return the bootstrap samples as a dataframe with an `Intercept` column and then one column for each independent variable. The function doesn't need to return the quantiles or the bootstrap standard error. Note that the column types of the data frame should be `float`.\n",
    "\n",
    "You can test the first function by making sure it gives you the same results as when you ran the logistic regression on the credit dataset above.  Once you've written the function, try it out on the credit dataset. You can use the `.quantile()` function on the returned data frame to compute the quantiles. You can also look at a pairplot of the bootstrap samples.\n",
    "\n",
    "**Remark:** You may need to set the `max_iter=1000` for the `LogisticRegression()`, as otherwise the model won't converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "def credit_linreg(credit):\n",
    "    X = credit.drop(columns=['Approved']).to_numpy(copy=True) \n",
    "    y = credit['Approved'].to_numpy()\n",
    "    model = LogisticRegression(max_iter=1000).fit(X, y)\n",
    "    coeffs = pd.concat([pd.Series(model.intercept_, index=['Intercept']),\n",
    "                        pd.Series(model.coef_[0], index=credit.columns.drop('Approved'))])\n",
    "    return(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = credit_linreg(credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_df(df, k=1000, estimator=credit_linreg):    \n",
    "    ## Main part of bootstrap\n",
    "    n = len(df)\n",
    "    coeffs = estimator(df)\n",
    "    x_star_est = pd.DataFrame(index=range(k), columns=coeffs.index, dtype='float')\n",
    "    for i in range(k):\n",
    "        x_star = df.sample(n, replace=True)\n",
    "        coeffs_star = estimator(x_star)      \n",
    "        x_star_est.loc[i] = coeffs_star\n",
    "    \n",
    "    return(x_star_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_bs = bootstrap_df(credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_bs.quantile([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(coeffs_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion** What can you conclude from the quantiles? Are any of the relationships you identified earlier open to question, because they may have arisen by chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Answer:\n",
    "\n",
    "Only `Intercept`, `YearsEmployed`, `NoPriorDefault`, `LogIncome`  and `LogCreditScore` have 95% confidence intervals that do not include zero. Remember that zero corresponds to no change in the log odds. The value zero is close to the centre of the confidence intervals for the other attributes (independent variables), suggesting that they are not significant relationships. We could imagine dropping the attributes whose coefficients appear to be close to zero.\n",
    "\n",
    "There are also some coefficients that are correlated. For example, bootstrap samples with a high coefficient for `Employed` tend to have a lower `LogCreditScore`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need your help:** This is a new course. In order for us to improve the labs for the next iterations, and to make sure that the next labs are better, we need your feedback. Please fill out the following [form](https://forms.office.com/Pages/ResponsePage.aspx?id=sAafLmkWiUWHiRCgaTTcYZmGMCx4KxlMjSTITqjdcXpUQkI2TUdDR1UwU0NBRE80OFVUMVRZM09KQi4u)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Standardised quantities\n",
    "\n",
    "By setting `max_iter=1000` we were able to ensure that the fitting of the logistic regression model converged. An alternative approach would be to standardise quantities. We can standardise the independent variables and then try fitting logistic regression again. However, the resulting coefficients will themselves be standardised, so we'll need to transform them back, to obtain the true figures. \n",
    "\n",
    "**Optional Exercise:** *If you're keen*, we suggest you just standardise the continuous variables. After running the same bootstrap function as above on the transformed data you can transform the parameters back using the formulae $\\beta_{Age} = \\frac{b_{Age}}{s_{Age}}$, where $b_{Age}$ is the transformed coefficient returned when the bootstrap function is applied to the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "credit_std = credit.copy()\n",
    "s = credit_std.std()\n",
    "xbar = credit_std.mean()\n",
    "credit_std['Age'] = credit_std['Age'].transform(lambda x: (x - xbar['Age'])/s['Age'])\n",
    "credit_std['LogIncome'] = credit_std['LogIncome'].transform(lambda x: (x - xbar['LogIncome'])/s['LogIncome'])\n",
    "credit_std['Debt'] = credit_std['Debt'].transform(lambda x: (x - xbar['Debt'])/s['Debt'])\n",
    "credit_std['YearsEmployed'] = credit_std['YearsEmployed'].transform(lambda x: (x - xbar['YearsEmployed'])/s['YearsEmployed'])\n",
    "credit_std['LogCreditScore'] = credit_std['LogCreditScore'].transform(lambda x: (x - xbar['LogCreditScore'])/s['LogCreditScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = bootstrap_df(credit_std)\n",
    "x_star['Intercept'] = (x_star['Intercept'] \n",
    "                       - x_star['Age']*xbar['Age']/s['Age'] \n",
    "                       - x_star['LogIncome']*xbar['LogIncome']/s['LogIncome']\n",
    "                       - x_star['Debt']*xbar['Debt']/s['Debt']\n",
    "                       - x_star['YearsEmployed']*xbar['YearsEmployed']/s['YearsEmployed']\n",
    "                       - x_star['LogCreditScore']*xbar['LogCreditScore']/s['LogCreditScore'])\n",
    "x_star['Age'] = x_star['Age']/s['Age']\n",
    "x_star['LogIncome'] = x_star['LogIncome']/s['LogIncome']\n",
    "x_star['Debt'] = x_star['Debt']/s['Debt']\n",
    "x_star['YearsEmployed'] = x_star['YearsEmployed']/s['YearsEmployed']\n",
    "x_star['LogCreditScore'] = x_star['LogCreditScore']/s['LogCreditScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star.quantile([0.025, 0.975])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
